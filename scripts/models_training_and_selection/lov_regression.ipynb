{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_management\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_preprocessing_pipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataPreprocessingPipeline\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, r2_score\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# Add project root to the Python path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.data_management.data_preprocessing_pipeline import DataPreprocessingPipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Loading dataset\n",
    "path = \"/Users/Macbook/Desktop/emergency-dept-optimization\"\n",
    "emergency_df = pd.read_sas(f\"{path}/nhamcs14.sas7bdat\")\n",
    "target = \"LOV\"\n",
    "\n",
    "# Instantiate the data preprocessing pipeline\n",
    "pipeline = DataPreprocessingPipeline(emergency_df=emergency_df,target=target,percent_train=0.7,percent_val=0.15,percent_test=0.15,path=path,stratify=False)\n",
    "\n",
    "# Run the pipeline\n",
    "pipeline.run()\n",
    "\n",
    "X_train = pipeline.X_train\n",
    "X_validation = pipeline.X_validation\n",
    "X_test = pipeline.X_test\n",
    "\n",
    "y_train = pipeline.y_train\n",
    "y_validation = pipeline.y_validation\n",
    "y_test = pipeline.X_test\n",
    "\n",
    "X_train_preprocessed = pipeline.X_train_preprocessed\n",
    "X_validation_preprocessed = pipeline.X_validation_preprocessed\n",
    "X_test_preprocessed = pipeline.X_test_preprocessed\n",
    "\n",
    "# MODEL TRAINING BELOW#\n",
    "\n",
    "# Define dictionary of models with their default parameters\n",
    "models_with_defaults = {\n",
    "    'LinearRegression': {\n",
    "        'model': LinearRegression()\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'model': Ridge()\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'model': Lasso()\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'model': GradientBoostingRegressor(random_state=42)\n",
    "    },\n",
    "    'XGBRegressor': {\n",
    "        'model': XGBRegressor(random_state=42)\n",
    "    },\n",
    "    'LGBMRegressor': {\n",
    "        'model': LGBMRegressor(random_state=42, force_col_wise=True, verbosity=-1)\n",
    "    },\n",
    "    'CatBoostRegressor': {\n",
    "        'model': CatBoostRegressor(verbose=0, random_seed=1)\n",
    "    } \n",
    "}\n",
    "\n",
    "# Initialize variables to track best model performance\n",
    "best_model = None\n",
    "best_mae = float('inf')  # Initialize with infinity\n",
    "best_r2 = -float('inf')   # Initialize with negative infinity\n",
    "\n",
    "# Define scoring metrics for cross-validation\n",
    "scoring = ['neg_mean_absolute_error', 'r2']\n",
    "\n",
    "# Loop over each model and evaluate their performance using cross-validation\n",
    "for model_name, model_info in models_with_defaults.items():\n",
    "    model = model_info['model']\n",
    "    print(f\"Cross-validating model {model_name}...\")\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = cross_validate(model, X_train_preprocessed, y_train, cv=5, scoring=scoring)\n",
    "    \n",
    "    # Calculate the average of the cross-validation scores\n",
    "    mean_mae_validation = -1 * cv_results['test_neg_mean_absolute_error'].mean()  # Make MAE positive\n",
    "    mean_r2_validation = cv_results['test_r2'].mean()\n",
    "    \n",
    "    # Print cross-validation metrics\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Cross-Validation MAE: {mean_mae_validation:.2f}\")\n",
    "    print(f\"Cross-Validation R-squared: {mean_r2_validation:.2f}\")\n",
    "    print()\n",
    "    \n",
    "    # Update best model if current model performs better based on MAE\n",
    "    if mean_mae_validation < best_mae and mean_r2_validation > best_r2:\n",
    "        best_model = model\n",
    "        best_model_name = model_name\n",
    "        best_mae = mean_mae_validation\n",
    "        best_r2 = mean_r2_validation\n",
    "\n",
    "# Print the best model and its cross-validation performance\n",
    "print(\"Best Model Based on Cross-Validation:\")\n",
    "print(f\"Model Name: {best_model_name}\")\n",
    "print(f\"Best Cross-Validation MAE: {best_mae:.2f}\")\n",
    "print(f\"Best Cross-Validation R-squared: {best_r2:.2f}\")\n",
    "\n",
    "# Create a directory to save the trained model\n",
    "model_train_dir = Path(\"model_train\")\n",
    "model_train_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save the best model using joblib\n",
    "joblib.dump(best_model, model_train_dir / f\"{best_model_name}.pkl\")\n",
    "print(f\"Best model saved as {best_model_name}.pkl in the 'model_train' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/Users/Macbook/Desktop/emergency-dept-optimization/src/model_training/model_train/LGBMRegressor.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edpredictiveefficiency",
   "language": "python",
   "name": "edpredictiveefficiency"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
