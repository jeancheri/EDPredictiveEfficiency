{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Cleaning data...\n",
      "Data cleaning completed\n",
      "Size of Initial dataset:(23844, 1012)\n",
      "Size of cleaned dataset:(21958, 408)\n",
      "\n",
      "2-Applying feature engineering...\n",
      "Feature engineering completed\n",
      "Size of the dataset after feature engineering:(21958, 445)\n",
      "\n",
      "3-Splitting data...\n",
      "self.stratify: False\n",
      "Splitting data completed\n",
      "\n",
      "4-Loading data...\n",
      "train_df size: (17566, 445)\n",
      "X_train size: (17566, 444)\n",
      "y_train size: (17566,)\n",
      "\n",
      "validation_df size: (2196, 445)\n",
      "X_validation size: (2196, 444)\n",
      "y_validation size: (2196,)\n",
      "\n",
      "test_df size: (2196, 445)\n",
      "X_test size: (2196, 444)\n",
      "y_test size: (2196,)\n",
      "Loading data completed\n",
      "\n",
      "5-Preprocessing data...\n",
      "Preprocessing data completed.\n",
      "Processor saved successfully\n",
      "y_test_waittime_classification dataset saved successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HOSPCODE\n",
       "2      266\n",
       "149    213\n",
       "244    162\n",
       "77     157\n",
       "189    156\n",
       "      ... \n",
       "72      10\n",
       "264      9\n",
       "177      9\n",
       "44       8\n",
       "9        8\n",
       "Name: count, Length: 239, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "import shap  # Import SHAP library\n",
    "import seaborn as sns  # Import Seaborn for visualization\n",
    "import matplotlib.pyplot as plt  # Import matplotlib for plotting\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_validate\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy import sparse as sp\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to the Python path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from src.data_management.data_preprocessing_pipeline import DataPreprocessingPipeline\n",
    "\n",
    "\n",
    "# Loading dataset\n",
    "path = \"/Users/jeancherizol/MADS/699/all_data\"\n",
    "path_models = \"/Users/jeancherizol/MADS/699/SIADS/emergency-dept-optimization/models\"\n",
    "emergency_df = pd.read_sas(f\"{path}/nhamcs14.sas7bdat\")\n",
    "\n",
    "\n",
    "target = 'WAITTIME_BINARY'\n",
    "target_to_drop = ['WAITTIME','LOV_BINARY']\n",
    "        \n",
    "# Instantiate the data preprocessing pipeline\n",
    "pipeline = DataPreprocessingPipeline(emergency_df=emergency_df,target=target,target_to_drop=target_to_drop,percent_train=0.80,percent_val=0.10,percent_test=0.10,path=path,stratify=False)\n",
    "\n",
    "# Run the pipeline\n",
    "pipeline.run()\n",
    "\n",
    "X_train = pipeline.X_train\n",
    "X_validation = pipeline.X_validation\n",
    "X_test = pipeline.X_test\n",
    "\n",
    "y_train = pipeline.y_train\n",
    "y_validation = pipeline.y_validation\n",
    "y_test = pipeline.y_test\n",
    "\n",
    "#Save target variable \n",
    "file_name = \"y_test_waittime_classification\"\n",
    "file_path = os.path.join(path, f\"{file_name}.csv\")\n",
    "y_test.to_csv(file_path, index=False)\n",
    "print(f\"{file_name} dataset saved successfully\")\n",
    "\n",
    "\n",
    "X_train_preprocessed = pipeline.X_train_preprocessed\n",
    "X_validation_preprocessed = pipeline.X_validation_preprocessed\n",
    "X_test_preprocessed = pipeline.X_test_preprocessed\n",
    "\n",
    "\n",
    "cleaned_emergency_df = pipeline.cleaned_emergency_df \n",
    "transformed_emergency_df = pipeline.transformed_emergency_df\n",
    "\n",
    "cleaned_emergency_df['HOSPCODE'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove prefixes and convert to list in one step if not already a list\n",
    "feature_names = [name.replace('num__', '').replace('cat__', '') for name in pipeline.feature_names]\n",
    "\n",
    "# Top 60 most important features\n",
    "# top_60_features = ['ARREMS', 'ARRTIME_IN_HOUR', 'DIFFEHRE', 'PATWT', 'DIAGSCRN', 'CSTRATM', 'EDINFO', 'NUMGIV', 'CPSUM', 'PHYSPRACTRIA', 'TOTDIAG', 'HOSPCODE', 'EMRED', 'IMMEDR', 'PULSE', 'WIRELESS', 'EMEDRES', 'BPSYS', 'EMSGE', 'RFV23D', 'RETREFFU', 'OTHPROV', 'MSA', 'EDPRIM', 'IVFLUIDS', 'FASTTRAK', 'TOTPROC', 'ESCRIPE', 'VMONTH', 'RFV33D', 'EREMINDE', 'EMSGER', 'BEDDATA', 'ADMDIV', 'MED1', 'DIAG3_-9', 'EGRAPHE', 'EBILLANYE', 'ESHAREPROVE2', 'EIDPTE', 'KIOSELCHK', 'CTHEAD', 'PAYMCAID', 'ECQMER', 'RFV2', 'AMBDIV', 'BPDIASD', 'ESHAREPROVE4', 'RFV1', 'PAYTYPER', 'URINECX', 'OTHERBLD', 'PROC', 'EPTRECE', 'RFV13D', 'ADVTRIAG', 'ESHAREPROVE7']\n",
    "top_60_features = ['LOV', 'ARREMS', 'ARRTIME_IN_HOUR', 'DIFFEHRE', 'PATWT', 'DIAGSCRN', 'CSTRATM', 'EDINFO', 'NUMGIV', 'CPSUM', 'PHYSPRACTRIA', 'TOTDIAG', 'HOSPCODE', 'EMRED', 'IMMEDR', 'PULSE', 'WIRELESS', 'EMEDRES', 'BPSYS', 'EMSGE', 'RFV23D', 'RETREFFU', 'OTHPROV', 'MSA', 'EDPRIM', 'IVFLUIDS', 'FASTTRAK', 'TOTPROC', 'ESCRIPE', 'VMONTH', 'RFV33D', 'EREMINDE', 'EMSGER', 'BEDDATA', 'ADMDIV', 'MED1', 'DIAG3_-9', 'EGRAPHE', 'EBILLANYE', 'ESHAREPROVE2', 'EIDPTE', 'KIOSELCHK', 'CTHEAD', 'PAYMCAID', 'ECQMER', 'RFV2', 'AMBDIV', 'BPDIASD', 'ESHAREPROVE4', 'RFV1', 'PAYTYPER', 'URINECX', 'OTHERBLD', 'PROC', 'EPTRECE', 'RFV13D', 'ADVTRIAG', 'ESHAREPROVE7']\n",
    "# # \n",
    "\n",
    "# Get indice of the top 60 most important features\n",
    "\n",
    "feature_indices = [feature_names.index(feature) for feature in top_60_features]\n",
    "\n",
    "# Get preprocessed data for the 60 most important features\n",
    "# These will be used to train the model and evaluate its parameters\n",
    "X_train_selected_features = X_train_preprocessed[:, feature_indices]\n",
    "X_validation_selected_features = X_validation_preprocessed[:, feature_indices]\n",
    "X_test_selected_features = X_test_preprocessed[:, feature_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f [2, 13, 382, 267, 381, 96, 379, 338, 208, 380, 361, 134, 261, 264, 31, 26, 366, 374, 28, 317, 40, 230, 226, 376, 337, 143, 362, 150, 287, 0, 41, 283, 318, 371, 352, 152, 3957, 299, 263, 329, 309, 357, 126, 18, 308, 35, 349, 216, 331, 34, 24, 119, 110, 135, 319, 39, 360, 334]\n"
     ]
    }
   ],
   "source": [
    "print('f',feature_indices )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'depth': 8, 'iterations': 100, 'l2_leaf_reg': 3, 'learning_rate': 0.1}\n",
      "Validation Metrics:\n",
      "F1 (Weighted): 0.73, ROC AUC: 0.82, Precision (Weighted): 0.76, Recall (Weighted): 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.78      1509\n",
      "           1       0.54      0.74      0.62       687\n",
      "\n",
      "    accuracy                           0.72      2196\n",
      "   macro avg       0.70      0.73      0.70      2196\n",
      "weighted avg       0.76      0.72      0.73      2196\n",
      "\n",
      "Class 0 - Precision: 0.86, Recall: 0.71, F1-score: 0.78\n",
      "Class 1 - Precision: 0.54, Recall: 0.74, F1-score: 0.62\n",
      "best_waittime_classification_catboost_model saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a range of hyperparameters for CatBoostClassifier\n",
    "param_grid = {\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'iterations': [30, 50, 100],\n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Initialize CatBoostClassifier with auto_class_weights set to 'Balanced'\n",
    "catboost_model = CatBoostClassifier(random_state=42, verbose=0, auto_class_weights='Balanced')\n",
    "\n",
    "# Configure GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=catboost_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring=make_scorer(f1_score, average='weighted'),  # Using make_scorer to specify average method\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "grid_search.fit(X_train_selected_features, y_train)\n",
    "\n",
    "# Retrieve and report the best hyperparameters\n",
    "best_hyperparams = grid_search.best_params_\n",
    "print(f\"Best hyperparameters: {best_hyperparams}\")\n",
    "\n",
    "# Training the final model with best hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_validation_pred = best_model.predict(X_validation_selected_features)\n",
    "y_validation_proba = best_model.predict_proba(X_validation_selected_features)[:, 1]  # For ROC AUC\n",
    "\n",
    "# Calculate metrics                                             \n",
    "f1_validation = f1_score(y_validation, y_validation_pred, average='weighted')\n",
    "roc_auc_validation = roc_auc_score(y_validation, y_validation_proba)\n",
    "precision_validation = precision_score(y_validation, y_validation_pred, average='weighted')\n",
    "recall_validation = recall_score(y_validation, y_validation_pred, average='weighted')\n",
    "\n",
    "print(f\"Validation Metrics:\\nF1 (Weighted): {f1_validation:.2f}, ROC AUC: {roc_auc_validation:.2f}, Precision (Weighted): {precision_validation:.2f}, Recall (Weighted): {recall_validation:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "#Metrics for each class\n",
    "# Generate a classification report\n",
    "report = classification_report(y_validation, y_validation_pred, output_dict=True)\n",
    "\n",
    "# Print out the classification report\n",
    "print(classification_report(y_validation, y_validation_pred))\n",
    "\n",
    "# For a more custom output, you can also access specific metrics from the report dictionary:\n",
    "for label, metrics in report.items():\n",
    "    if label not in ('accuracy', 'macro avg', 'weighted avg'):\n",
    "        print(f\"Class {label} - Precision: {metrics['precision']:.2f}, Recall: {metrics['recall']:.2f}, F1-score: {metrics['f1-score']:.2f}\")\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "model_filename = f\"{path_models}/best_waittime_classification_catboost_model.joblib\"\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(\"best_waittime_classification_catboost_model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "# from sklearn.metrics import make_scorer, f1_score, classification_report\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# import joblib\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the stratified K-fold for the imbalanced dataset\n",
    "# cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# # Setup scoring function\n",
    "# scoring = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# # Function to create a pipeline and tune a given model\n",
    "# def create_pipeline_and_tune(model_name, model, param_dist, X_train, y_train):\n",
    "#     pipeline = Pipeline([\n",
    "#         ('smote', SMOTE(random_state=42)),\n",
    "#         (model_name, model)\n",
    "#     ])\n",
    "#     random_search = RandomizedSearchCV(\n",
    "#         estimator=pipeline,\n",
    "#         param_distributions=param_dist,\n",
    "#         n_iter=10,\n",
    "#         cv=cv_strategy,\n",
    "#         scoring=scoring,\n",
    "#         verbose=1,\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1\n",
    "#     )\n",
    "#     random_search.fit(X_train, y_train)\n",
    "#     return random_search.best_estimator_[model_name]\n",
    "\n",
    "# # Define parameter distributions and models\n",
    "# models_param_dist = {\n",
    "#     'xgb': {\n",
    "#         'xgb__n_estimators': [100, 200, 300],\n",
    "#         'xgb__max_depth': [3, 5, 7],\n",
    "#         'xgb__learning_rate': np.logspace(-3, -1, 3),\n",
    "#     },\n",
    "#     'catboost': {\n",
    "#         'catboost__depth': [4, 6, 8],\n",
    "#         'catboost__learning_rate': np.logspace(-3, -1, 3),\n",
    "#         'catboost__iterations': [100, 200, 300],\n",
    "#     },\n",
    "#     'gb': {\n",
    "#         'gb__n_estimators': [100, 200, 300],\n",
    "#         'gb__learning_rate': np.logspace(-3, -1, 3),\n",
    "#         'gb__max_depth': [3, 5, 7],\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Tuning models\n",
    "# models = {\n",
    "#     'xgb': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "#     'catboost': CatBoostClassifier(verbose=0, random_state=42, auto_class_weights='Balanced'),\n",
    "#     'gb': GradientBoostingClassifier(random_state=42)\n",
    "# }\n",
    "\n",
    "# best_models = {}\n",
    "# for name, model in models.items():\n",
    "#     print(f\"Tuning {name}...\")\n",
    "#     best_models[name] = create_pipeline_and_tune(name, model, models_param_dist[name], X_train, y_train)\n",
    "\n",
    "# # Define and train the ensemble model\n",
    "# ensemble_model = VotingClassifier(\n",
    "#     estimators=[(name, best_models[name]) for name in best_models],\n",
    "#     voting='soft'\n",
    "# )\n",
    "\n",
    "# final_pipeline = Pipeline([\n",
    "#     ('smote', SMOTE(random_state=42)),\n",
    "#     ('ensemble', ensemble_model)\n",
    "# ])\n",
    "\n",
    "# final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on validation set and evaluate\n",
    "# y_validation_pred = final_pipeline.predict(X_validation)\n",
    "# print(classification_report(y_validation, y_validation_pred))\n",
    "\n",
    "# # Save the final model\n",
    "# model_filename = f\"{path_models}/best_waittime_classification_catboost_model.joblib\"\n",
    "# joblib.dump(final_pipeline, model_filename)\n",
    "# print(f\"{model_filename} saved\")\n",
    "\n",
    "\n",
    "# # # Save the final model\n",
    "# # model_filename = f\"{path_models}/best_waittime_classification_catboost_model.joblib\"\n",
    "# # joblib.dump(final_pipeline, model_filename)\n",
    "# # print(f\"{model_filename} saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOSPCODE: 31\n",
      "Classification Report for 31:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.71         7\n",
      "   macro avg       0.71      0.71      0.71         7\n",
      "weighted avg       0.71      0.71      0.71         7\n",
      "\n",
      "\n",
      "\n",
      "HOSPCODE: 91\n",
      "Classification Report for 91:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.73      0.73      0.73         8\n",
      "weighted avg       0.75      0.75      0.75         8\n",
      "\n",
      "\n",
      "\n",
      "HOSPCODE: 101\n",
      "Classification Report for 101:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.68      0.68      0.68        13\n",
      "weighted avg       0.69      0.69      0.69        13\n",
      "\n",
      "\n",
      "\n",
      "HOSPCODE: 116\n",
      "Classification Report for 116:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        12\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.79      0.79      0.79        15\n",
      "weighted avg       0.87      0.87      0.87        15\n",
      "\n",
      "\n",
      "\n",
      "HOSPCODE: 149\n",
      "Classification Report for 149:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81        17\n",
      "           1       0.56      0.71      0.62         7\n",
      "\n",
      "    accuracy                           0.75        24\n",
      "   macro avg       0.71      0.74      0.72        24\n",
      "weighted avg       0.78      0.75      0.76        24\n",
      "\n",
      "\n",
      "\n",
      "HOSPCODE: 153\n",
      "Classification Report for 153:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.60      0.75      0.67         4\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.70      0.71      0.70        10\n",
      "weighted avg       0.72      0.70      0.70        10\n",
      "\n",
      "\n",
      "\n",
      "HOSPCODE: 154\n",
      "Classification Report for 154:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.78         9\n",
      "   macro avg       0.75      0.75      0.75         9\n",
      "weighted avg       0.78      0.78      0.78         9\n",
      "\n",
      "\n",
      "\n",
      "HOSPCODE: 217\n",
      "Classification Report for 217:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.75      0.75      0.75         8\n",
      "weighted avg       0.75      0.75      0.75         8\n",
      "\n",
      "\n",
      "\n",
      "HOSPCODE: 233\n",
      "Classification Report for 233:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80        10\n",
      "           1       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.70      0.70      0.70        15\n",
      "weighted avg       0.73      0.73      0.73        15\n",
      "\n",
      "\n",
      "\n",
      "HOSPCODE: 243\n",
      "Classification Report for 243:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.62         8\n",
      "           1       0.56      0.83      0.67         6\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.68      0.67      0.64        14\n",
      "weighted avg       0.70      0.64      0.64        14\n",
      "\n",
      "\n",
      "\n",
      "List of HOSPCODEs meeting the criteria:\n",
      "[31, 91, 101, 116, 149, 153, 154, 217, 233, 243]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "# Assuming the best_model has been trained and is available\n",
    "# Assuming X_test_selected_features, y_test, and HOSPCODEs are properly defined\n",
    "HOSPCODEs_test = X_test['HOSPCODE'].values\n",
    "\n",
    "# Prediction\n",
    "y_test_pred = best_model.predict(X_test_selected_features)\n",
    "# For binary classification tasks\n",
    "y_test_proba = best_model.predict_proba(X_test_selected_features)[:, 1]\n",
    "\n",
    "# Assuming HOSPCODEs_test contains the HOSPCODE for each record in X_test_selected_features\n",
    "predictions_df = pd.DataFrame({\n",
    "    'HOSPCODE': HOSPCODEs_test,\n",
    "    'y_true': y_test,\n",
    "    'y_pred': y_test_pred,\n",
    "    'y_proba': y_test_proba\n",
    "})\n",
    "\n",
    "# Placeholder for aggregated results\n",
    "results_per_hospcode = {}\n",
    "\n",
    "valid_hospcode_list = []\n",
    "\n",
    "for code, group in predictions_df.groupby('HOSPCODE'):\n",
    "    report = classification_report(group['y_true'], group['y_pred'], output_dict=True, zero_division=0)\n",
    "    metrics = precision_recall_fscore_support(group['y_true'], group['y_pred'], average=None, zero_division=0)\n",
    "    \n",
    "    # Unpack metrics for both classes\n",
    "    precision_values, recall_values, f1_values, _ = metrics\n",
    "    \n",
    "    # Check if F1 scores for both classes are greater than 0.60 and precision and recall are less than 1\n",
    "    if all(f1 >= 0.60 for f1 in f1_values) and all(p < 1 and r < 1 for p, r in zip(precision_values, recall_values)):\n",
    "        valid_hospcode_list.append(code)\n",
    "        \n",
    "        # Displaying results for valid HOSPCODE\n",
    "        print(f\"HOSPCODE: {code}\")\n",
    "        print(f\"Classification Report for {code}:\")\n",
    "        print(classification_report(group['y_true'], group['y_pred'], zero_division=0))\n",
    "        print(\"\\n\")\n",
    "\n",
    "print(\"List of HOSPCODEs meeting the criteria:\")\n",
    "print(valid_hospcode_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emergency-dept-optimization-VxYDoEAm-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
